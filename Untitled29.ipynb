{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2524ef31-9650-49d6-977e-1614f2e28704",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandas numpy scikit-learn xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14002211-0a23-41af-9781-963900577548",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f8106b-0057-4131-8c43-9e38c5088508",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Monday-WorkingHours.pcap_ISCX.csv\")\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "df = df.replace([np.inf, -np.inf], np.nan)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "df['Label'] = df['Label'].apply(lambda x: 0 if x == 'BENIGN' else 1)\n",
    "\n",
    "df.to_csv(\"processed_monday.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d078cf-f267-4668-b328-1baa2884360c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Tuesday-WorkingHours.pcap_ISCX.csv\")\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "df = df.replace([np.inf, -np.inf], np.nan)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "df['Label'] = df['Label'].apply(lambda x: 0 if x == 'BENIGN' else 1)\n",
    "\n",
    "df.to_csv(\"processed_tuesday.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65eac02c-5e8b-4836-bd67-6e654a914ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Wednesday-workingHours.pcap_ISCX.csv\")\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "df = df.replace([np.inf, -np.inf], np.nan)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "df['Label'] = df['Label'].apply(lambda x: 0 if x == 'BENIGN' else 1)\n",
    "\n",
    "df.to_csv(\"processed_wednesday.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19785081-95b1-49b0-9e06-bb51707651de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX.csv\")\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "df = df.replace([np.inf, -np.inf], np.nan)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "df['Label'] = df['Label'].apply(lambda x: 0 if x == 'BENIGN' else 1)\n",
    "\n",
    "df.to_csv(\"processed_thursday_morning.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1810d976-16ae-48a0-9a3e-f66d3fd16fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Thursday-WorkingHours-Afternoon-Infilteration.pcap_ISCX.csv\")\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "df = df.replace([np.inf, -np.inf], np.nan)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "df['Label'] = df['Label'].apply(lambda x: 0 if x == 'BENIGN' else 1)\n",
    "\n",
    "df.to_csv(\"processed_thursday_afternoon.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9939a3-6e40-4c43-9060-ff3a9b510487",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Friday-WorkingHours-Morning.pcap_ISCX.csv\")\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "df = df.replace([np.inf, -np.inf], np.nan)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "df['Label'] = df['Label'].apply(lambda x: 0 if x == 'BENIGN' else 1)\n",
    "\n",
    "df.to_csv(\"processed_friday_morning.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bada57d7-6dc9-4860-baaa-8c0da61796eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX.csv\")\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "df = df.replace([np.inf, -np.inf], np.nan)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "df['Label'] = df['Label'].apply(lambda x: 0 if x == 'BENIGN' else 1)\n",
    "\n",
    "df.to_csv(\"processed_friday_portscan.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4acf79-35a4-4076-9c85-09e6ae8790ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv\")\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "df = df.replace([np.inf, -np.inf], np.nan)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "df['Label'] = df['Label'].apply(lambda x: 0 if x == 'BENIGN' else 1)\n",
    "\n",
    "df.to_csv(\"processed_friday_ddos.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991a2ca8-960b-46fe-9461-43b6254cbc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "files = [\n",
    "    \"processed_monday.csv\",\n",
    "    \"processed_tuesday.csv\",\n",
    "    \"processed_wednesday.csv\",\n",
    "    \"processed_thursday_morning.csv\",\n",
    "    \"processed_thursday_afternoon.csv\",\n",
    "    \"processed_friday_morning.csv\",\n",
    "    \"processed_friday_portscan.csv\",\n",
    "    \"processed_friday_ddos.csv\"\n",
    "]\n",
    "\n",
    "for f in files:\n",
    "    df = pd.read_csv(f)\n",
    "    print(f, \"â†’\", df['Label'].value_counts().to_dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad69bca7-8782-4305-8137-02dcad3bf208",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "files = [\n",
    "    \"processed_monday.csv\",\n",
    "    \"processed_tuesday.csv\",\n",
    "    \"processed_wednesday.csv\",\n",
    "    \"processed_thursday_morning.csv\",\n",
    "    \"processed_thursday_afternoon.csv\",\n",
    "    \"processed_friday_morning.csv\",\n",
    "    \"processed_friday_portscan.csv\",\n",
    "    \"processed_friday_ddos.csv\"\n",
    "]\n",
    "\n",
    "dfs = [pd.read_csv(f) for f in files]\n",
    "data = pd.concat(dfs, axis=0, ignore_index=True)\n",
    "\n",
    "print(\"FINAL LABEL DISTRIBUTION:\")\n",
    "print(data['Label'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d717e74-73c6-4976-afa9-e43e05ecfb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert set(data['Label'].unique()) == {0, 1}\n",
    "print(\"âœ… Dataset verified: both classes present\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ae4b9a-c6be-4368-a73e-5346e15da614",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = data.drop('Label', axis=1)\n",
    "y = data['Label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(\"Train distribution:\\n\", y_train.value_counts())\n",
    "print(\"Test distribution:\\n\", y_test.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad5cc20-866d-4765-a81a-53c7b66a1689",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b93d19-6379-4e7b-b598-7ad0f757e4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "import numpy as np\n",
    "\n",
    "iso = IsolationForest(\n",
    "    n_estimators=100,\n",
    "    contamination=0.1,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "iso.fit(X_train_scaled)\n",
    "\n",
    "train_anomaly = iso.decision_function(X_train_scaled)\n",
    "test_anomaly = iso.decision_function(X_test_scaled)\n",
    "\n",
    "X_train_if = np.column_stack((X_train_scaled, train_anomaly))\n",
    "X_test_if = np.column_stack((X_test_scaled, test_anomaly))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2754e74-b034-4d8c-85d3-70c79a0d3883",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from collections import Counter\n",
    "\n",
    "counter = Counter(y_train)\n",
    "scale_pos_weight = counter[0] / counter[1]\n",
    "\n",
    "xgb = XGBClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective='binary:logistic',\n",
    "    eval_metric='logloss',\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "xgb.fit(X_train_if, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150e0afe-a261-4ecf-b951-160a2290cb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "y_pred = xgb.predict(X_test_if)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1768dd-f7a4-4c29-a676-56b6aad33871",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['BENIGN', 'ATTACK'],\n",
    "            yticklabels=['BENIGN', 'ATTACK'])\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"Actual Label\")\n",
    "plt.title(\"Confusion Matrix Heatmap\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebac145-7926-4b28-8f8f-545c570543e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select top 15 features based on variance\n",
    "top_features = data.drop('Label', axis=1).var().sort_values(ascending=False).head(15).index\n",
    "\n",
    "corr = data[top_features].corr()\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(corr, cmap='coolwarm', linewidths=0.5)\n",
    "plt.title(\"Feature Correlation Heatmap (Top 15 Features)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a2a741-9e08-442a-9051-7936f5624af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,4))\n",
    "sns.countplot(x=data['Label'])\n",
    "plt.xticks([0,1], ['BENIGN', 'ATTACK'])\n",
    "plt.title(\"Class Distribution in CICIDS2017 Dataset\")\n",
    "plt.ylabel(\"Number of Samples\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ceb16e-1419-4bbe-b124-4e2a393a2023",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.hist(train_anomaly, bins=50)\n",
    "plt.xlabel(\"Anomaly Score\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Isolation Forest Anomaly Score Distribution\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986aebf9-9627-4f07-9cb9-f505444ec31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "y_prob = xgb.predict_proba(X_test_if)[:, 1]\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "auc = roc_auc_score(y_test, y_prob)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label=f\"AUC = {auc:.3f}\")\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec4c152-c6bc-48ab-aecb-b992efdf8643",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "fp = cm[0, 1]\n",
    "fn = cm[1, 0]\n",
    "\n",
    "plt.figure()\n",
    "plt.bar([\"False Positives\", \"False Negatives\"], [fp, fn])\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"False Positives vs False Negatives\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e498c73c-013b-44f4-a535-b282b2e0e304",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = xgb.predict(X_test_if)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec4a4fb-df4f-4da5-a677-34338c9c5479",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob = xgb.predict_proba(X_test_if)[:, 1]\n",
    "\n",
    "# Increase threshold\n",
    "threshold = 0.7\n",
    "y_pred_custom = (y_prob >= threshold).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441c3ac4-eb4a-4081-850c-435db90ffde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred_custom)\n",
    "fp = cm[0, 1]\n",
    "fn = cm[1, 0]\n",
    "\n",
    "print(\"FP:\", fp)\n",
    "print(\"FN:\", fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a80a7f-3950-492e-be35-9287796f70ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob = xgb.predict_proba(X_test_if)[:, 1]\n",
    "\n",
    "threshold = 0.8   # try 0.7 â†’ 0.75 â†’ 0.8\n",
    "y_pred_new = (y_prob >= threshold).astype(int)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred_new)\n",
    "FP = cm[0,1]\n",
    "FN = cm[1,0]\n",
    "\n",
    "print(\"FP:\", FP)\n",
    "print(\"FN:\", FN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68a8948-6282-47cd-af4f-1e73a9a3930e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#zero day attack\n",
    "\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Separate benign and attack samples\n",
    "benign_data = data[data['Label'] == 0]\n",
    "attack_data = data[data['Label'] == 1]\n",
    "\n",
    "X_benign = benign_data.drop('Label', axis=1)\n",
    "X_attack = attack_data.drop('Label', axis=1)\n",
    "\n",
    "# Scale using only benign traffic\n",
    "scaler_zd = StandardScaler()\n",
    "X_benign_scaled = scaler_zd.fit_transform(X_benign)\n",
    "X_attack_scaled = scaler_zd.transform(X_attack)\n",
    "\n",
    "# Train Isolation Forest ONLY on BENIGN traffic\n",
    "iso_zero_day = IsolationForest(\n",
    "    n_estimators=100,\n",
    "    contamination=0.02,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "iso_zero_day.fit(X_benign_scaled)\n",
    "\n",
    "# Predict anomalies\n",
    "benign_pred = iso_zero_day.predict(X_benign_scaled)\n",
    "attack_pred = iso_zero_day.predict(X_attack_scaled)\n",
    "\n",
    "print(\"Benign detected as anomaly (FP):\", (benign_pred == -1).sum())\n",
    "print(\"Attacks detected as anomaly (TP):\", (attack_pred == -1).sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560066b7-cbc6-4195-8f6b-7cdf5f4b4cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ground truth for zero-day test\n",
    "# Benign = 0, Attack = 1\n",
    "y_true_zero = (\n",
    "    [0] * len(benign_pred) +\n",
    "    [1] * len(attack_pred)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103246b6-dead-459c-911e-c81c3b70e217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert predictions to labels\n",
    "y_pred_zero = (\n",
    "    [0 if p == 1 else 1 for p in benign_pred] +\n",
    "    [0 if p == 1 else 1 for p in attack_pred]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db9264b-4b74-45f2-aa8c-a385d0709bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "zero_day_accuracy = accuracy_score(y_true_zero, y_pred_zero)\n",
    "print(\"Zero-Day Detection Accuracy:\", zero_day_accuracy)\n",
    "\n",
    "print(classification_report(y_true_zero, y_pred_zero))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0185d3-f081-4f1b-a3c3-e75bba79da53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate benign and attack samples\n",
    "benign_data = data[data['Label'] == 0]\n",
    "attack_data = data[data['Label'] == 1]\n",
    "\n",
    "X_benign = benign_data.drop('Label', axis=1)\n",
    "X_attack = attack_data.drop('Label', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fc5c50-4713-4ed9-a339-6e9db84201a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_benign_scaled = scaler.fit_transform(X_benign)\n",
    "X_attack_scaled = scaler.transform(X_attack)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711daa64-6818-4bec-bd75-ca46cd5bd644",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "iso_zero_day = IsolationForest(\n",
    "    n_estimators=100,\n",
    "    contamination=0.02,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "iso_zero_day.fit(X_benign_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d2581c-4f46-405e-a307-4892b092bcf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on benign and attack data\n",
    "benign_pred = iso_zero_day.predict(X_benign_scaled)\n",
    "attack_pred = iso_zero_day.predict(X_attack_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6081d6-eb0e-4c6d-89ff-8872146eecb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ground truth\n",
    "y_true = ([0] * len(benign_pred)) + ([1] * len(attack_pred))\n",
    "\n",
    "# Predicted labels\n",
    "y_pred = (\n",
    "    [0 if p == 1 else 1 for p in benign_pred] +\n",
    "    [0 if p == 1 else 1 for p in attack_pred]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f96530-cfba-41d1-8a87-a01a34c208be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "print(\"Zero-Day Detection Accuracy:\",\n",
    "      accuracy_score(y_true, y_pred))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\\n\",\n",
    "      confusion_matrix(y_true, y_pred))\n",
    "\n",
    "print(\"\\nClassification Report:\\n\",\n",
    "      classification_report(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13936698-5e55-4125-86dc-58b03d054eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#concept drift\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Train on early traffic\n",
    "train_files = [\n",
    "    \"processed_monday.csv\",\n",
    "    \"processed_tuesday.csv\"\n",
    "]\n",
    "\n",
    "# Test on later traffic (drift)\n",
    "test_files = [\n",
    "    \"processed_friday_portscan.csv\",\n",
    "    \"processed_friday_ddos.csv\"\n",
    "]\n",
    "\n",
    "train_df = pd.concat([pd.read_csv(f) for f in train_files], axis=0)\n",
    "test_df = pd.concat([pd.read_csv(f) for f in test_files], axis=0)\n",
    "\n",
    "X_train_drift = train_df.drop('Label', axis=1)\n",
    "y_train_drift = train_df['Label']\n",
    "\n",
    "X_test_drift = test_df.drop('Label', axis=1)\n",
    "y_test_drift = test_df['Label']\n",
    "\n",
    "scaler_drift = StandardScaler()\n",
    "X_train_drift_scaled = scaler_drift.fit_transform(X_train_drift)\n",
    "X_test_drift_scaled = scaler_drift.transform(X_test_drift)\n",
    "\n",
    "# Train model on old data\n",
    "xgb_drift = XGBClassifier(\n",
    "    n_estimators=150,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    eval_metric='logloss',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "xgb_drift.fit(X_train_drift_scaled, y_train_drift)\n",
    "\n",
    "# Test on new data\n",
    "y_pred_drift = xgb_drift.predict(X_test_drift_scaled)\n",
    "\n",
    "print(\"Accuracy under concept drift:\",\n",
    "      accuracy_score(y_test_drift, y_pred_drift))\n",
    "\n",
    "print(classification_report(y_test_drift, y_pred_drift))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2761c4da-0eee-4eae-a573-696a889f281f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain using new (Friday) data\n",
    "combined_df = pd.concat([train_df, test_df], axis=0)\n",
    "\n",
    "X_new = combined_df.drop('Label', axis=1)\n",
    "y_new = combined_df['Label']\n",
    "\n",
    "scaler_new = StandardScaler()\n",
    "X_new_scaled = scaler_new.fit_transform(X_new)\n",
    "\n",
    "xgb_drift.fit(X_new_scaled, y_new)\n",
    "\n",
    "# Test again\n",
    "y_pred_retrained = xgb_drift.predict(X_test_drift_scaled)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy after retraining:\",\n",
    "      accuracy_score(y_test_drift, y_pred_retrained))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42768403-1f88-40bf-a824-f7161da32233",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Time-based chunks (ordered)\n",
    "chunks = [\n",
    "    \"processed_monday.csv\",\n",
    "    \"processed_tuesday.csv\",\n",
    "    \"processed_wednesday.csv\",\n",
    "    \"processed_thursday_morning.csv\",\n",
    "    \"processed_friday_ddos.csv\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d3474c-1c18-409e-b325-9ed01f064e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "monday = pd.read_csv(\"processed_monday.csv\")\n",
    "tuesday = pd.read_csv(\"processed_tuesday.csv\")\n",
    "\n",
    "# Optional: take only a small part of Tuesday attacks\n",
    "tuesday_attack = tuesday[tuesday['Label'] == 1].sample(n=5000, random_state=42)\n",
    "tuesday_benign = tuesday[tuesday['Label'] == 0].sample(n=5000, random_state=42)\n",
    "\n",
    "train_df = pd.concat([monday, tuesday_attack, tuesday_benign], axis=0)\n",
    "\n",
    "print(\"Seed dataset label distribution:\")\n",
    "print(train_df['Label'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a96ac1-af67-40fe-9d04-464939ddadad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "X_train = train_df.drop('Label', axis=1)\n",
    "y_train = train_df['Label']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "model = XGBClassifier(\n",
    "    n_estimators=150,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    objective='binary:logistic',\n",
    "    eval_metric='logloss',\n",
    "    base_score=0.5,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "model.fit(X_train_scaled, y_train)\n",
    "print(\"âœ… Initial model trained successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a6a0fe-c914-414b-9202-166d1fc50352",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = [\n",
    "    \"processed_wednesday.csv\",\n",
    "    \"processed_thursday_morning.csv\",\n",
    "    \"processed_friday_ddos.csv\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17538e56-83b4-470d-80dc-3d4dd0faaa67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "results = []\n",
    "\n",
    "for file in chunks:\n",
    "    print(f\"\\nðŸ“¥ New incoming data: {file}\")\n",
    "    \n",
    "    new_df = pd.read_csv(file)\n",
    "    \n",
    "    X_new = new_df.drop('Label', axis=1)\n",
    "    y_new = new_df['Label']\n",
    "    \n",
    "    X_new_scaled = scaler.transform(X_new)\n",
    "    \n",
    "    # ðŸ”¹ Performance BEFORE retraining (concept drift effect)\n",
    "    y_pred_before = model.predict(X_new_scaled)\n",
    "    acc_before = accuracy_score(y_new, y_pred_before)\n",
    "    \n",
    "    # ðŸ”¹ Incremental update (append new data)\n",
    "    train_df = pd.concat([train_df, new_df], axis=0)\n",
    "    \n",
    "    X_train = train_df.drop('Label', axis=1)\n",
    "    y_train = train_df['Label']\n",
    "    \n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # ðŸ”¹ Performance AFTER retraining\n",
    "    y_pred_after = model.predict(X_new_scaled)\n",
    "    acc_after = accuracy_score(y_new, y_pred_after)\n",
    "    \n",
    "    results.append((file, acc_before, acc_after))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430f6f3a-4e0a-4114-984b-81ea38e49967",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nðŸ“Š Incremental Retraining Results\")\n",
    "for f, before, after in results:\n",
    "    print(f\"{f}\")\n",
    "    print(f\"  Accuracy before retraining : {before:.3f}\")\n",
    "    print(f\"  Accuracy after retraining  : {after:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf53e54-05fc-4459-869b-d4d2a5875d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_before = accuracy_score(y_new, y_pred_before)\n",
    "print(\"Accuracy before retraining (concept drift):\", acc_before)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb118a9-a1bc-42b9-9423-1a85c0784b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_after = accuracy_score(y_new, y_pred_after)\n",
    "print(\"Accuracy after incremental retraining:\", acc_after)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68664a00-da8c-4cda-afe3-936b61f614ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = xgb.predict(X_test_if)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed29cca-f16a-4fa2-98a1-6dfdf1ebb146",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Baseline Accuracy:\", baseline_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac6c7c6-d746-4ff8-86e3-7d6fa30a28e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = pd.DataFrame({\n",
    "    \"Scenario\": [\n",
    "        \"Normal Training (No Drift)\",\n",
    "        \"Zero-Day Attack Detection\",\n",
    "        \"Concept Drift (Before Retraining)\",\n",
    "        \"Concept Drift (After Retraining)\"\n",
    "    ],\n",
    "    \"Accuracy\": [\n",
    "        baseline_accuracy,      # from your main model\n",
    "        zero_day_accuracy,\n",
    "        acc_before,\n",
    "        acc_after\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(summary)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
